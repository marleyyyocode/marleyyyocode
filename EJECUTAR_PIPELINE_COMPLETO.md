# ğŸš€ GuÃ­a de EjecuciÃ³n - Pipeline Completo BNB

## ğŸ“‹ DescripciÃ³n

Este pipeline implementa optimizaciÃ³n individual de hiperparÃ¡metros para cada modelo (LSTM Univariado, CNN Univariado, LSTM Multivariado) y genera proyecciones de precios 15 dÃ­as hacia el futuro.

## â±ï¸ Tiempo de EjecuciÃ³n

**Total estimado: 30-40 minutos**

- LSTM Univariado tuning: ~10-12 min (20 experimentos)
- CNN Univariado tuning: ~10-12 min (20 experimentos)  
- LSTM Multivariado tuning: ~10-12 min (20 experimentos)
- EvaluaciÃ³n y proyecciones: ~3-5 min
- Visualizaciones: ~2 min

## ğŸ”§ Requisitos Previos

```bash
# Instalar dependencias
pip install -r requirements.txt
```

## ğŸš€ EjecuciÃ³n

### OpciÃ³n 1: Script Completo Integrado (RECOMENDADO)

```bash
python run_complete_pipeline.py
```

Este script ejecuta automÃ¡ticamente:
1. âœ… PreparaciÃ³n de datos y EDA
2. âœ… OptimizaciÃ³n individual de hiperparÃ¡metros (3 modelos)
3. âœ… EvaluaciÃ³n en test set
4. âœ… GeneraciÃ³n de proyecciones (15 dÃ­as)
5. âœ… Todas las visualizaciones

### OpciÃ³n 2: Ejecutar solo el mÃ³dulo original

```bash
python Codigo_GrupoBNB.py
```

*(No incluye optimizaciÃ³n individual ni proyecciones)*

## ğŸ“Š Outputs Generados

### Modelos Optimizados
```
models/
â”œâ”€â”€ baseline_model_optimized.pkl
â”œâ”€â”€ lstm_univariado_optimized.h5
â”œâ”€â”€ cnn_univariado_optimized.h5
â””â”€â”€ lstm_multivariado_optimized.h5
```

### Visualizaciones de Tuning (10 paneles cada una)
```
outputs/
â”œâ”€â”€ tuning_lstm_univariado.png      # AnÃ¡lisis de hiperparÃ¡metros LSTM
â”œâ”€â”€ tuning_cnn_univariado.png       # AnÃ¡lisis de hiperparÃ¡metros CNN
â””â”€â”€ tuning_lstm_multivariado.png    # AnÃ¡lisis de hiperparÃ¡metros LSTM Multi
```

**Cada visualizaciÃ³n incluye:**
- Learning Rate comparaciÃ³n
- Arquitectura (capas/filtros) comparaciÃ³n
- FunciÃ³n de ActivaciÃ³n
- Dropout Rate
- Batch Size
- Optimizador
- FunciÃ³n de PÃ©rdida
- RegularizaciÃ³n L2
- Top 10 mejores configuraciones
- Resumen de mejor configuraciÃ³n (panel verde)

### Visualizaciones de Proyecciones
```
outputs/
â””â”€â”€ projections_all_models.png      # 6 paneles:
                                     #   - 4 modelos individuales
                                     #   - 1 comparaciÃ³n conjunta
                                     #   - 1 panel de info
```

### Datos
```
metrics_optimized.csv          # MÃ©tricas finales (MSE, MAE, RÂ²)
projections_15_days.csv        # Proyecciones de los 4 modelos
```

## ï¿½ï¿½ HiperparÃ¡metros Optimizados

### LSTM Univariado (20 experimentos)
- **Learning rates**: 0.001, 0.005, 0.01
- **Arquitecturas**: 
  - 2 capas: [64, 32]
  - 3 capas: [128, 64, 32]
  - 4 capas: [256, 128, 64, 32]
- **Activaciones**: relu, tanh
- **Dropout**: 0.1, 0.2, 0.3
- **Batch sizes**: 16, 32
- **Optimizadores**: Adam, RMSprop
- **Loss**: MSE, MAE
- **L2 Reg**: 0.0, 0.001

### CNN Univariado (20 experimentos)
- **Learning rates**: 0.0001, 0.0005, 0.001
- **Arquitecturas Conv**:
  - 2 capas: [32, 64]
  - 2 capas: [64, 128]
  - 2 capas: [128, 256]
- **Kernel sizes**: 3, 5
- **Activaciones**: relu, elu
- **Dropout**: 0.1, 0.2, 0.3
- **Batch sizes**: 16, 32
- **Optimizadores**: Adam, RMSprop
- **Loss**: MSE, MAE
- **L2 Reg**: 0.0, 0.001

### LSTM Multivariado (20 experimentos)
*(Similar a LSTM Univariado, optimizado para 3 features: High, Volume, Volatility)*

## ğŸ¯ CaracterÃ­sticas Clave

âœ… **OptimizaciÃ³n Individual por Modelo**
- Cada modelo encuentra sus hiperparÃ¡metros Ã³ptimos
- Incluye hiperparÃ¡metros arquitectÃ³nicos (capas, unidades, filtros)
- Total: ~60 experimentos (20 por modelo)

âœ… **Proyecciones Multi-Paso**
- 15 dÃ­as hacia el futuro
- ProyecciÃ³n iterativa para todos los modelos
- VisualizaciÃ³n comparativa

âœ… **Sin Early Stopping**
- Como se requiriÃ³ en las especificaciones
- Ã‰pocas fijas (80) para cada experimento

âœ… **Reproducibilidad**
- Seed fija (SEED=42) en Python, NumPy, TensorFlow
- Resultados reproducibles

## ğŸ’¡ InterpretaciÃ³n de Resultados

### Visualizaciones de Tuning

**Panel verde = Mejor valor** para cada hiperparÃ¡metro

Cada grÃ¡fico muestra:
- Valor promedio de validation loss para cada configuraciÃ³n
- Mejor valor resaltado en verde
- Permite identificar quÃ© hiperparÃ¡metros tienen mayor impacto

### MÃ©tricas

**Baseline (RegresiÃ³n Lineal)** = Referencia
- Si deep learning NO supera al baseline â†’ Datos tienen patrones lineales
- Si deep learning supera â†’ CapturÃ³ patrones no-lineales complejos

**RÂ² (Coeficiente de DeterminaciÃ³n)**:
- 1.0 = PredicciÃ³n perfecta
- 0.9+ = Excelente
- 0.8-0.9 = Bueno
- <0.8 = Regular/Necesita mejora

**MSE y MAE**:
- Menor es mejor
- MSE penaliza errores grandes mÃ¡s fuertemente
- MAE es mÃ¡s interpretable (error promedio en USD)

### Proyecciones

- **LÃ­nea azul**: Datos reales (test set)
- **LÃ­neas de colores**: Proyecciones de cada modelo
- **LÃ­nea vertical punteada**: Inicio de proyecciÃ³n

**Divergencia entre modelos** = Incertidumbre sobre precios futuros

## ğŸ› Troubleshooting

### Error: `ModuleNotFoundError`
```bash
pip install -r requirements.txt
```

### Error: `No module named 'enhanced_additions'`
AsegÃºrate de estar en el directorio correcto:
```bash
cd /path/to/marleyyyocode/
python run_complete_pipeline.py
```

### Proceso muy lento
- Normal para 60 experimentos (~30-40 min)
- Puedes monitorear el progreso en la consola
- Cada experimento muestra su nÃºmero y validation loss

### Out of Memory
- Reduce batch size en experimentos
- Ejecuta en mÃ¡quina con mÃ¡s RAM
- O ejecuta modelos por separado

## ğŸ“ Notas Importantes

1. **Datos SintÃ©ticos**: Si yfinance API falla, el cÃ³digo usa datos sintÃ©ticos automÃ¡ticamente. Los resultados siguen siendo vÃ¡lidos para demostrar el pipeline.

2. **GPU vs CPU**: El cÃ³digo funciona en ambos. GPU es mÃ¡s rÃ¡pido pero no es necesario.

3. **Resultados Variables**: Aunque usamos seed=42, pequeÃ±as variaciones pueden ocurrir debido a operaciones no-deterministas en TensorFlow.

4. **Almacenamiento**: AsegÃºrate de tener ~100MB libres para modelos y visualizaciones.

## ğŸ“š Estructura del CÃ³digo

```
marleyyyocode/
â”œâ”€â”€ Codigo_GrupoBNB.py              # Pipeline base original
â”œâ”€â”€ enhanced_additions.py           # Funciones de tuning + proyecciones
â”œâ”€â”€ run_complete_pipeline.py        # Script integrado ejecutable
â”œâ”€â”€ EJECUTAR_PIPELINE_COMPLETO.md   # Esta guÃ­a
â”œâ”€â”€ requirements.txt                # Dependencias
â”œâ”€â”€ models/                         # Modelos entrenados (generado)
â”œâ”€â”€ outputs/                        # Visualizaciones (generado)
â””â”€â”€ scalers/                        # Scalers guardados (generado)
```

## ğŸ“ Referencias

- **LSTM**: https://www.tensorflow.org/api_docs/python/tf/keras/layers/LSTM
- **Conv1D**: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv1D
- **Time Series**: https://www.tensorflow.org/tutorials/structured_data/time_series

## âœ… Checklist de EjecuciÃ³n

- [ ] Dependencias instaladas (`pip install -r requirements.txt`)
- [ ] Directorio correcto (donde estÃ¡ `run_complete_pipeline.py`)
- [ ] Espacio en disco suficiente (~100MB)
- [ ] Tiempo disponible (~30-40 min)
- [ ] Ejecutar: `python run_complete_pipeline.py`
- [ ] Revisar outputs en `models/` y `outputs/`
- [ ] Verificar mÃ©tricas en `metrics_optimized.csv`
- [ ] Analizar proyecciones en `projections_15_days.csv`

---

**Â¡Listo para ejecutar!** ğŸš€

Para dudas o problemas, revisar la secciÃ³n de Troubleshooting arriba.
